[
	{
		"id": "kCOmMg9AsRxnuSmxQm116xcUOHtV123fEQuhFJvM6TQrgB116cDAZ3R13600d5evKIb8LGRHydIRJEZWYfiBXs6K6DQw117117",
		"name": "AlchemyAPI",
		"summary": "The product of over 50 person years of engineering effort, AlchemyAPI is a text mining platform providing the most comprehensive set of semantic analysis capabilities in the natural language processing field. Used over 3 billion times every month, AlchemyAPI enables customers to perform large-scale social media monitoring, target advertisements more effectively, track influencers and sentiment wit",
		"details": "The product of over 50 person years of engineering effort, AlchemyAPI is a text mining platform providing the most comprehensive set of semantic analysis capabilities in the natural language processing field. Used over 3 billion times every month, AlchemyAPI enables customers to perform large-scale social media monitoring, target advertisements more effectively, track influencers and sentiment within the media, automate content aggregation and recommendation, make more accurate stock trading decisions, enhance business and government intelligence systems, and create smarter applications and services.",
		"website": "http://www.alchemyapi.com/",
		"twitter": "https://twitter.com/alchemyapi",
		"github": "https://github.com/AlchemyAPI",
		"apisjson_url": "http://theapistack.com/data/alchemyapi/apis.json",
		"portal_url": "https://github.com/AlchemyAPI",
		"base_url": "http://www.alchemyapi.com/developers",
		"blog": "http://blog.alchemyapi.com/",
		"blogrss": "http://blog.alchemyapi.com/rss.xml",
		"logo": "https://avatars.githubusercontent.com/u/4061718?v=3",
		"logo_width": "175",
		"screenshot": "https://avatars.githubusercontent.com/u/4061718?v=3",
		"tags": [
			"Stack Network",
			"Semantic Analysis",
			"Scraping",
			"My API Stack",
			"Machine Learning Scraping",
			"Language",
			"Getting Started Example",
			"Content Analysis",
			"Content"
		]
	},
	{
		"id": "PM3r7KVO5v6aUFJbvS1BR0Lf3p40HvyY1o7W4ybnGnzqc02XvuBMO36KqnuknGSNQFFg5h116n0MvKnudTBQWhvQ117117",
		"name": "Apache Nutch",
		"summary": "Nutch is a well matured, production ready Web crawler. Nutch 1.x enables fine grained configuration, relying on Apache Hadoopu0026trade; data structures, which are great for batch processing. - See more at: http://nutch.apache.org/index.html#sthash.dehuG4St.dpuf",
		"details": "Nutch is a well matured, production ready Web crawler. Nutch 1.x enables fine grained configuration, relying on Apache Hadoopu0026trade; data structures, which are great for batch processing. - See more at: http://nutch.apache.org/index.html#sthash.dehuG4St.dpuf",
		"website": "http://nutch.apache.org/",
		"twitter": "",
		"github": "",
		"apisjson_url": "",
		"portal_url": "",
		"base_url": "",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/apache-nutch.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/apache-nutch.jpg",
		"tags": [
			"Scraping",
			"Profiled",
			"API Tool"
		]
	},
	{
		"id": "z4FNFbLf9k99bqPCYPW116XP3vpLMK116IP9j5ykdu90bMtIriVGR5UN3WjtS9gpGFV3eqILIMAVC1R0D7LIbzXHwQ117117",
		"name": "Apifier",
		"summary": "Apify extracts data from websites, crawls lists of URLs and automates workflows on the web. Turn any website into an API in a few minutes!",
		"details": "Apify extracts data from websites, crawls lists of URLs and automates workflows on the web. Turn any website into an API in a few minutes!",
		"website": "https://www.apifier.com/",
		"twitter": "https://twitter.com/ApifierInfo",
		"github": "https://github.com/apifier",
		"apisjson_url": "",
		"portal_url": "https://github.com/apifier",
		"base_url": "https://www.apifier.com/docs",
		"blog": "https://blog.apifier.com/",
		"blogrss": "https://blog.apifier.com/feed",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/20035-apifier.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/20035-apifier.jpg",
		"tags": [
			"Web Crawler",
			"Technology",
			"Scraping Web Crawler",
			"Scraping",
			"SaaS",
			"Profiled",
			"API Service Provider"
		]
	},
	{
		"id": "JQvndkfG6rF6wUim5gURrdkxm7GSl5YXHOSEE9TOiCoPNd2ytsIH1KHm123XdsrP43CpDumKuw3123jGs123HopNNRGw117117",
		"name": "Aylien",
		"summary": "Text Analysis API | Natural Language Processing",
		"details": "Text Analysis API | Natural Language Processing",
		"website": "http://aylien.com/",
		"twitter": "https://twitter.com/_aylien",
		"github": "https://github.com/AYLIEN",
		"apisjson_url": "",
		"portal_url": "https://github.com/AYLIEN",
		"base_url": "https://newsapi.aylien.com/",
		"blog": "http://blog.aylien.com/",
		"blogrss": "http://blog.aylien.com/rss",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/20034-aylien.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/20034-aylien.jpg",
		"tags": [
			"Technology",
			"Service Level Agreement",
			"Scraping",
			"SaaS",
			"Profiled",
			"Machine Learning Scraping",
			"Machine Learning",
			"Enterprise",
			"Content",
			"API Provider"
		]
	},
	{
		"id": "2w9fLBSE1U7km6HSSGjBhnvzud116fJ6B8NihiGfLQyu2o2rVobeNZMiborJtsNh1wY12399SBP6WVrgx1Z7jWmgJA117117",
		"name": "CommonCrawl",
		"summary": "CommonCrawl is a non-profit foundation dedicated to the open web.",
		"details": "CommonCrawl is a non-profit foundation dedicated to the open web.",
		"website": "http://commoncrawl.org/",
		"twitter": "https://twitter.com/CommonCrawl",
		"github": "https://github.com/commoncrawl",
		"apisjson_url": "http://theapistack.com/data/commoncrawl/apis.json",
		"portal_url": "https://github.com/commoncrawl",
		"base_url": "",
		"blog": "http://commoncrawl.org/blog/",
		"blogrss": "http://commoncrawl.org/feed/",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/1920-commoncrawl.jpg",
		"logo_width": "175",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/1920-commoncrawl.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Search",
			"Scraping Web Crawler",
			"Scraping",
			"Profiled",
			"internet",
			"API Service Provider",
			"API Provider"
		]
	},
	{
		"id": "WD2123xoBlxicqGSQxI4pkqYdu2FWlDw56HzhPTy3KT0TfQLqt9zQJOTHp116EuQ7OSF116M08hO9orAjKxD4RNzHfcQ117117",
		"name": "ConvExtra",
		"summary": "Convextra allows you collect valuable data from internet and represents it in easy-to-use CVS format for forther utilization.",
		"details": "Convextra allows you collect valuable data from internet and represents it in easy-to-use CVS format for forther utilization.",
		"website": "http://convextra.com/",
		"twitter": "",
		"github": "",
		"apisjson_url": "http://theapistack.com/data/convextra/apis.json",
		"portal_url": "",
		"base_url": "",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/convextra-logo.png",
		"logo_width": "175",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/convextra-logo.png",
		"tags": [
			"Scraping Tools",
			"Scraping",
			"Scraping"
		]
	},
	{
		"id": "wx0S106xuQ2cHbevzz8U1237bFPFulocR35JqRS8X8FCNUQs7qrnY0oZG63bYL123mCEMxGlRXPyy6GRem1qJnR5gg117117",
		"name": "Dandelion API",
		"summary": "Semantic Text Analytics API: From text to actionable data: extract meaning from unstructured text and put it in context with a simple API.",
		"details": "Semantic Text Analytics API: From text to actionable data: extract meaning from unstructured text and put it in context with a simple API.",
		"website": "https://dandelion.eu",
		"twitter": "https://twitter.com/dandelionapi",
		"github": "",
		"apisjson_url": "",
		"portal_url": "",
		"base_url": "",
		"blog": "http://blog.dandelion.eu/",
		"blogrss": "http://blog.dandelion.eu/feed/",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/18951-dandelion-api.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/18951-dandelion-api.jpg",
		"tags": [
			"Technology",
			"Scraping",
			"SaaS",
			"Profiled",
			"Machine Learning Scraping",
			"Machine Learning",
			"Machine Learning",
			"API Provider"
		]
	},
	{
		"id": "hBSGEqF9J1YEYaW8fMXm9dS3r5fpE2aaqt116bNJOjGQKhvslDaRbWucPQrOkItSRghs8NWtg2JNpXJC4sgU3a6A117117",
		"name": "Diffbot",
		"summary": "Never write another web scraper. Diffbot automates web data extraction from any website using AI, computer vision, u0026amp; machine learning.",
		"details": "Never write another web scraper. Diffbot automates web data extraction from any website using AI, computer vision, u0026amp; machine learning.",
		"website": "http://www.diffbot.com/our-apis/follow/",
		"twitter": "https://twitter.com/diffbot",
		"github": "https://github.com/diffbot",
		"apisjson_url": "http://theapistack.com/data/deskero/apis.json",
		"portal_url": "https://github.com/diffbot",
		"base_url": "",
		"blog": "http://diffbot.com/blog",
		"blogrss": "http://www.diffbot.com/api/rss/www.diffbot.com/blog",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/181-diffbot.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/181-diffbot.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Scraping",
			"SaaS",
			"Profiled",
			"Machine Learning Scraping",
			"Machine Learning",
			"internet",
			"Extraction",
			"Crawler",
			"Content",
			"API Service Provider",
			"API Provider"
		]
	},
	{
		"id": "F9MsdhMfLNCnqQouVylvvqsYQ4s2iVoaS7w116P9QrOMoq58mozmLpoR1Nn9tw123gM116xzjuamTECqnMgGIcXbSrWg117117",
		"name": "Diggernaut",
		"summary": "Web scraping just became easy. Extract any website content and turn it into data sets. No programming skills required.u0026nbsp; We also help larger accounts where we can do custom programming to collect the data to perform business intelligence, competitive pricing, market sentiment, and other forms of analysis.",
		"details": "Web scraping just became easy. Extract any website content and turn it into data sets. No programming skills required.u0026nbsp; We also help larger accounts where we can do custom programming to collect the data to perform business intelligence, competitive pricing, market sentiment, and other forms of analysis.",
		"website": "https://www.diggernaut.com",
		"twitter": "https://twitter.com/diggernautcom",
		"github": null,
		"apisjson_url": null,
		"portal_url": null,
		"base_url": null,
		"blog": "https://www.diggernaut.com/blog/",
		"blogrss": null,
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/28731-www-diggernaut-com.jpg",
		"logo_width": null,
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/28731-www-diggernaut-com.jpg",
		"tags": [
			"Scraping",
			"SaaS",
			"Enterprise"
		]
	},
	{
		"id": "v8JAjFi53tKqc123vD116Bu3W1CoTRWT9s116kDDHtY8b4t15TwrBf1gDjWZOzPf3akxAuUpST7lSGBaqTEB123tVPMpvA117117",
		"name": "Embedly",
		"summary": "Extract allows you to mine important features within articles???so you can use written content how you want to. Control colors, text, keywords, and entities in any article on your site. Remove extraneous information. As you automate the way you use articles, you???ll gain insight into your users??? preferences, helping you serve them better.",
		"details": "Extract allows you to mine important features within articles???so you can use written content how you want to. Control colors, text, keywords, and entities in any article on your site. Remove extraneous information. As you automate the way you use articles, you???ll gain insight into your users??? preferences, helping you serve them better.",
		"website": "http://embed.ly/extract",
		"twitter": "https://twitter.com/embedly",
		"github": "https://github.com/embedly",
		"apisjson_url": "",
		"portal_url": "https://github.com/embedly",
		"base_url": "",
		"blog": "https://twitter.com/weogeostatus",
		"blogrss": "http://blog.embed.ly/rss",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/190-embedly.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/190-embedly.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Social",
			"Scraping Tools",
			"Scraping",
			"SaaS",
			"Profiled",
			"internet",
			"Embeddable",
			"Embed",
			"API Service Provider"
		]
	},
	{
		"id": "ny5QIpkGNknxe0PxdI6m2GhOqfTq19HErArKPU0XGWg5BjMpM4arEiuc1163hL1Li123FgJB8SzEaDtXqvLLQ1165XVw117117",
		"name": "HPE Haven OnDemand",
		"summary": "Haven OnDemand is an API platform for building data rich applications using text analysis, speech recognition, image analysis, indexing and search APIs.",
		"details": "Haven OnDemand is an API platform for building data rich applications using text analysis, speech recognition, image analysis, indexing and search APIs.",
		"website": "https://www.havenondemand.com/",
		"twitter": "https://twitter.com/HavenOnDemand",
		"github": "https://github.com/HPE-Haven-OnDemand",
		"apisjson_url": "",
		"portal_url": "https://github.com/HPE-Haven-OnDemand",
		"base_url": "https://dev.havenondemand.com/",
		"blog": "https://community.havenondemand.com/t5/Blog/bg-p/blog_iod",
		"blogrss": "https://community.havenondemand.com/etmmh37422/rss/boardmessages?board.id=blog_iod",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/20037-hpe-haven-ondemand.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/20037-hpe-haven-ondemand.jpg",
		"tags": [
			"Technology",
			"Scraping",
			"SaaS",
			"Machine Learning Scraping",
			"Machine Learning",
			"Enterprise"
		]
	},
	{
		"id": "Ja8ZQ3F0bXJxTKzxlxhhTcK70NZcl11603wB8OA1dP0L4GL1S7VCCwmCRSLJFGJ0XpDc9saa61233116MEwB8S1239Fddg117117",
		"name": "Import.io",
		"summary": "Import.io turns the web into a database, releasing the vast potential of data trapped in websites. Allowing you to identify a website, select the data and treat it as a table in your database. In effect transform the data into a row and column format. You can then add more websites to your data set, the same as adding more rows and query in real-time to access the data.",
		"details": "Import.io turns the web into a database, releasing the vast potential of data trapped in websites. Allowing you to identify a website, select the data and treat it as a table in your database. In effect transform the data into a row and column format. You can then add more websites to your data set, the same as adding more rows and query in real-time to access the data.",
		"website": "https://www.import.io/",
		"twitter": "https://twitter.com/importio",
		"github": "https://github.com/import-io",
		"apisjson_url": "http://theapistack.com/data/importio/apis.json",
		"portal_url": "https://github.com/import-io",
		"base_url": "",
		"blog": "http://blog.import.io/",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/1728-import-io.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/1728-import-io.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Scraping",
			"SaaS",
			"Profiled",
			"API United Kingdom",
			"API Service Provider",
			"API Provider"
		]
	},
	{
		"id": "Vz1168nsP6ucPCvpEpcUSprGZ1X123Ejb6E9Sb7WKx0QT4ruygFBe8PoRknvaUB3WfJFklZtAd2XeR116olCPFdk1HKQ117117",
		"name": "link.fish",
		"summary": "Automatically get the information of the websites you are interested in and work with it together with others in real-time. Depending on the page you bookmark link.fish automatically extracts the data you actually care about. No matter if bedrooms for apartments, rating of movies or the cook time of your favorite recipe. Invite other people to your collection to work with them or make it public fo",
		"details": "Automatically get the information of the websites you are interested in and work with it together with others in real-time. Depending on the page you bookmark link.fish automatically extracts the data you actually care about. No matter if bedrooms for apartments, rating of movies or the cook time of your favorite recipe. Invite other people to your collection to work with them or make it public for everbody to see. All changes made will immediately be visible by everyone.",
		"website": "http://link.fish",
		"twitter": "https://twitter.com/linkfish_",
		"github": "https://github.com/link-fish",
		"apisjson_url": "",
		"portal_url": "https://github.com/link-fish",
		"base_url": "https://link.fish/api/",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/link-fish-logo.png",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/link-fish-logo.png",
		"tags": [
			"Scraping",
			"Profiled",
			"Links",
			"Content",
			"API Provider"
		]
	},
	{
		"id": "AuV11674guokWDRAU5oZgKrl8pMfHM9mvFBlJfGPF3PHjUrQF5aNNz1ArYbNlcgcIx2Ptk9uVETAFCRi0vRdYDxQ117117",
		"name": "Moz",
		"summary": "Backed by the largest community of SEOs on the planet, Moz builds tools that make SEO, inbound marketing, link building, and content marketing easy. Start your free 30-day trial today!",
		"details": "Backed by the largest community of SEOs on the planet, Moz builds tools that make SEO, inbound marketing, link building, and content marketing easy. Start your free 30-day trial today!",
		"website": "https://moz.com",
		"twitter": "https://twitter.com/moz",
		"github": "https://github.com/seomoz",
		"apisjson_url": "",
		"portal_url": "https://github.com/seomoz",
		"base_url": "https://moz.com/products/api",
		"blog": "https://moz.com/blog",
		"blogrss": "http://feedpress.me/mozblog",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/18952-moz.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/18952-moz.jpg",
		"tags": [
			"Web Crawler",
			"Technology",
			"Target",
			"Stack Network",
			"Scraping Web Crawler",
			"Scraping",
			"SaaS",
			"Profiled",
			"Links",
			"internet"
		]
	},
	{
		"id": "T116eEQuLCdJymEj6Xr123SRSQWsLShZVmXhSZ5e9ThOxfOUQvCCSdg67v3vLBJE88eIwQrpT1167E2vcFA3bd66DI7w117117",
		"name": "Mozenda",
		"summary": "Over 7 billion web pages harvested since 2007. trusted by thousands of customers worldwide. Stellar account management and customer support.",
		"details": "Over 7 billion web pages harvested since 2007. trusted by thousands of customers worldwide. Stellar account management and customer support.",
		"website": "http://www.mozenda.com",
		"twitter": "http://www.twitter.com/mozenda",
		"github": "",
		"apisjson_url": "",
		"portal_url": "",
		"base_url": "",
		"blog": "http://www.mozenda.com/blog/",
		"blogrss": "http://www.mozenda.com/blog/?feed=rss2",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/1919-mozenda.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/1919-mozenda.jpg",
		"tags": [
			"Technology",
			"Scraping Tools",
			"Scraping",
			"SaaS",
			"Profiled",
			"Enterprise",
			"API Provider"
		]
	},
	{
		"id": "Q6y9wvc123B0u1fjcaJSJdtcWCage9FBC72OnSdR3gsLfLgC1dpa6rd7cdYSOE2FVSCe2aybr811648As0kYv5ISig117117",
		"name": "ParseHub",
		"summary": "ParseHub is a free web scraping tool.              With our advanced web scraper, extracting data is as easy as              clicking the data you need.",
		"details": "ParseHub is a free web scraping tool.              With our advanced web scraper, extracting data is as easy as              clicking the data you need.",
		"website": "https://www.parsehub.com/",
		"twitter": "https://twitter.com/parsehub",
		"github": "https://github.com/parsehub",
		"apisjson_url": "http://theapistack.com/data/parsehub/apis.json",
		"portal_url": "https://github.com/parsehub",
		"base_url": "",
		"blog": "https://blog.parsehub.com/",
		"blogrss": "https://blog.parsehub.com/rss/",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/11394-parsehub.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/11394-parsehub.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Scraping Tools",
			"Scraping",
			"SaaS"
		]
	},
	{
		"id": "IgVxcWUe0nJAMeslGn1U1nXA07rq123B8AB116eIULWnUXk3tEqR1Iru7wsZN96ftuqbvEhTpVbjg123wrc2FD2VxrlQ117117",
		"name": "PromptCloud",
		"summary": "Our web scraping service helps companies get the data they want, the way they need it. We use web crawling, web scraping and data extraction technologies to deliver clean and ready-to-use data.",
		"details": "Our web scraping service helps companies get the data they want, the way they need it. We use web crawling, web scraping and data extraction technologies to deliver clean and ready-to-use data.",
		"website": "http://promptcloud.com/",
		"twitter": "https://twitter.com/promptcloud",
		"github": "https://github.com/promptcloud",
		"apisjson_url": "http://theapistack.com/data/promptcloud/apis.json",
		"portal_url": "https://github.com/promptcloud",
		"base_url": "https://www.promptcloud.com/promptcloud-api-documentation/",
		"blog": "http://blog.promptcloud.com/",
		"blogrss": "http://blog.promptcloud.com/feeds/posts/default?alt=rss",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/2511-promptcloud.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/2511-promptcloud.jpg",
		"tags": [
			"Technology",
			"Scraping Web Crawler",
			"Scraping",
			"Scraping",
			"SaaS",
			"internet",
			"Enterprise"
		]
	},
	{
		"id": "V116qWHJ3Qa9V4wwia116kBu4cnPvXeesSkdYJMwxA0RqC6INwhTXGBHWzSt1iP1yMfr5bZ8x4zVBuOYwOwZjcqPfA117117",
		"name": "Saplo",
		"summary": "Saplo uses innovative semantic technologies to analyze text in a way that mimic how humans read and evaluate text. Saplo help organisations extract and refine valuable information hidden in large text collections. Saplo have five different services; Entity Tagging, Topic Tags, Related u0026amp; Similar Articles, Contextual recognition and Sentiment Analysis.",
		"details": "Saplo uses innovative semantic technologies to analyze text in a way that mimic how humans read and evaluate text. Saplo help organisations extract and refine valuable information hidden in large text collections. Saplo have five different services; Entity Tagging, Topic Tags, Related u0026amp; Similar Articles, Contextual recognition and Sentiment Analysis.",
		"website": "http://saplo.com",
		"twitter": "https://twitter.com/saplo",
		"github": "https://github.com/saplo",
		"apisjson_url": "http://theapistack.com/data/saplo/apis.json",
		"portal_url": "https://github.com/saplo",
		"base_url": "http://developer.saplo.com/",
		"blog": "http://saplo.com/blog/",
		"blogrss": "http://feeds.feedburner.com/saplo/",
		"logo": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/469_logo.png",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/469_logo.png",
		"tags": [
			"Text Analysis",
			"Scraping",
			"Machine Learning Scraping",
			"Content"
		]
	},
	{
		"id": "116JUTarbSrYSaZKcPUozvBrISqrhkGSPepn3iFGLE7nb9u2PXYgUIRlqZOJ6G62GYpzBV8uK5jmIjJepj116Mawmg117117",
		"name": "ScrapeLogo",
		"summary": "ScrapeLogo has been discovered and developed by Maintop Businesses, originally only for internal purposes. It was coded as an independent service for several Maintopu0026rsquo;s B2B projects. When requests from other companies multiplied, a private beta version was launched too. We are now looking for the first beta testers, who would like to show company logos on their websites and help us improve th",
		"details": "ScrapeLogo has been discovered and developed by Maintop Businesses, originally only for internal purposes. It was coded as an independent service for several Maintopu0026rsquo;s B2B projects. When requests from other companies multiplied, a private beta version was launched too. We are now looking for the first beta testers, who would like to show company logos on their websites and help us improve the quality and precision of our algorithm.",
		"website": "http://scrapelogo.com/",
		"twitter": "",
		"github": "",
		"apisjson_url": "http://theapistack.com/data/scrapelogo/apis.json",
		"portal_url": "",
		"base_url": "http://scrapelogo.com/dead-simple-api/",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/scrape-logo.png",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/scrape-logo.png",
		"tags": [
			"Scraping Tools",
			"Scraping",
			"Logo"
		]
	},
	{
		"id": "Ku1tJw7eZKd3d9123cperVoVCDwpzwx16cgJ1hcE028NjKsf2GPzW6QR123pUGiFhNJL3UqrJHUUUq31VTh5SxuD123g117117",
		"name": "ScraperWiki",
		"summary": "ScraperWiki the company is now called @sensiblecodeio. ScraperWiki the product is https://t.co/k0MbgXFINE. Also try our other product https://t.co/gp7nY2c3w5.",
		"details": "ScraperWiki the company is now called @sensiblecodeio. ScraperWiki the product is https://t.co/k0MbgXFINE. Also try our other product https://t.co/gp7nY2c3w5.",
		"website": "https://scraperwiki.com/",
		"twitter": "https://twitter.com/scraperwiki",
		"github": "https://github.com/scraperwiki",
		"apisjson_url": "",
		"portal_url": "https://github.com/scraperwiki",
		"base_url": "",
		"blog": "https://blog.scraperwiki.com/blog/",
		"blogrss": "https://blog.scraperwiki.com/feed/",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/247-scraperwiki.jpg",
		"logo_width": "175",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/247-scraperwiki.jpg",
		"tags": [
			"Technology",
			"Scraping",
			"SaaS",
			"internet",
			"Enterprise"
		]
	},
	{
		"id": "R1116k2EkFf78nTAeegnssl9uqHjxhrX53h42MXaeiVWn6s3bvBGsuAYlTTqcRU70UeY5wF7e5hHH0G3Su1230gX2Q117117",
		"name": "Scrapinghub",
		"summary": "Complete platform for turning web pages into useful data!",
		"details": "Complete platform for turning web pages into useful data!",
		"website": "http://scrapinghub.com/",
		"twitter": "https://twitter.com/ScrapingHub",
		"github": "https://github.com/scrapinghub",
		"apisjson_url": "",
		"portal_url": "https://github.com/scrapinghub",
		"base_url": "",
		"blog": "http://blog.scrapinghub.com/",
		"blogrss": "http://blog.scrapinghub.com/feed/",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/2509-scrapinghub.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/2509-scrapinghub.jpg",
		"tags": [
			"Technology",
			"Scrapinging",
			"Scraping Web Crawler",
			"Scraping Tools",
			"Scraping",
			"SaaS",
			"Enterprise"
		]
	},
	{
		"id": "pmOJncRLyB5p5NWI36aKwIeTfinPgCpzsDDLNo6obU4nog62VrEn7xGfO5Qq1160lzv9WFtX0bOvl82SXM3FXybw117117",
		"name": "Scrapy",
		"summary": "The most popular open source web scraping framework in Python.",
		"details": "The most popular open source web scraping framework in Python.",
		"website": "http://scrapy.org/",
		"twitter": "https://twitter.com/ScrapyProject",
		"github": "https://github.com/scrapy",
		"apisjson_url": "",
		"portal_url": "https://github.com/scrapy",
		"base_url": "",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/11435-scrapy.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/11435-scrapy.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Scraping Tools",
			"Scraping",
			"SaaS",
			"Harvesting"
		]
	},
	{
		"id": "MDLBQ1nKzTqnEsInH508dPPRNkOu7npfqggCUCQpK64iHsUzwEyAriHkzVzilctZcr6Hr7KUcvvnLpRHrZB123uQ117117",
		"name": "Screen Scraper",
		"summary": "Web Data Extraction",
		"details": "Web Data Extraction",
		"website": "http://screen-scraper.com/",
		"twitter": "",
		"github": "",
		"apisjson_url": "http://theapistack.com/data/screen-scraper/apis.json",
		"portal_url": "",
		"base_url": "http://community.screen-scraper.com/",
		"blog": "http://blog.screen-scraper.com/",
		"blogrss": "http://feeds.feedburner.com/screen-scrapeable",
		"logo": "https://s3.amazonaws.com/kinlane-productions/api-evangelist/api-butterfly.png",
		"logo_width": "175",
		"screenshot": "https://s3.amazonaws.com/kinlane-productions/api-evangelist/api-butterfly.png",
		"tags": [
			"Technology",
			"Scraping Tools",
			"Scraping",
			"Scraping",
			"SaaS",
			"Enterprise"
		]
	},
	{
		"id": "uI6pkmQZZTtoB2TfcSTyL673f1dc86p7OmU7TgZfRYgu3RnecKKOAKm7eelSnzwAkdE7N9iobgSlCm86yKS43g117117",
		"name": "TextRazor",
		"summary": "The service provides analysis of selected text passages to identify named entities and statements of fact with disambiguation to distinguish similar text strings. It applies machine learning algorithms and natural language processing to connect a text sample with a knowledge base and identify known elements and their relationships. API methods support submission of a text sample to be parsed.u0026nbsp",
		"details": "The service provides analysis of selected text passages to identify named entities and statements of fact with disambiguation to distinguish similar text strings. It applies machine learning algorithms and natural language processing to connect a text sample with a knowledge base and identify known elements and their relationships. API methods support submission of a text sample to be parsed.u0026nbsp;",
		"website": "http://www.textrazor.com",
		"twitter": "https://twitter.com/TextRazor",
		"github": "https://github.com/TextRazor",
		"apisjson_url": "http://theapistack.com/data/textrazor/apis.json",
		"portal_url": "https://github.com/TextRazor",
		"base_url": "http://www.textrazor.com/documentation_rest",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/textrazor.gif",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/logos/textrazor.gif",
		"tags": [
			"Target",
			"Stack Network",
			"Semantic",
			"Scraping",
			"Machine Learning Scraping",
			"Machine Learning",
			"Content"
		]
	},
	{
		"id": "m9KSY8Y123slwwjIuypI22wPDP0QjUfLo1y64v116dJhZf6b3FvCcfJCzuGekVXNICVVeGwurpKds5gVf1166r3BXuJw117117",
		"name": "WrapAPI",
		"summary": "Build an API on top of any website. Turn any website...into a parameterized APIBuild, share, and use APIs made from webpages. Use WrapAPI to scrape sites, build better UIs, and automate online tasks.",
		"details": "Build an API on top of any website. Turn any website...into a parameterized APIBuild, share, and use APIs made from webpages. Use WrapAPI to scrape sites, build better UIs, and automate online tasks.",
		"website": "https://wrapapi.com",
		"twitter": "",
		"github": "",
		"apisjson_url": "",
		"portal_url": "",
		"base_url": "",
		"blog": "",
		"blogrss": "",
		"logo": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/19089-wrapapi.jpg",
		"logo_width": "150",
		"screenshot": "http://kinlane-productions.s3.amazonaws.com/screen-capture-api/19089-wrapapi.jpg",
		"tags": [
			"Technology",
			"Stack Network",
			"Scraping Tools",
			"Scraping",
			"SaaS",
			"internet",
			"Deployment"
		]
	}
]