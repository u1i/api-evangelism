---
published: true
layout: post
title: Automating Inequality (and APIs)
date: 2018-08-06T09:00:00.000Z
tags:
  - API Evangelist
  - Politics of APIs
  - Privacy
image: >-
  https://s3.amazonaws.com/kinlane-productions/events/apistrat-2018/apistrat-virginia.png
---
<p><img src="{{ page.image }}" width="45%" align="right" style="padding: 15px;" /></p>_As we prepare for [APIStrat in Nashville, TN this September 24th through 26th](https://events.linuxfoundation.org/events/apistrat-2018/program/), I asked my partner in crime Audrey Watters ([@audreywatters](https://twitter.com/audreywatters)) to write a post on the significance of Virginia Eubanks, the author of Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor keynoting the conference--she shared this story, of why her work is so significant, and why it is important for the API community to tune in._

Repeatable tasks can and should be automated -- that's an assertion that you'll hear all the time in computing.

Sometimes the rationale is efficiency -- it's cheaper, faster, "labor-saving." Automation will free up time; it will make our lives easier. Or so we're told.

Sometimes automation is encouraged in order to eliminate human error or bias.

Increasingly, automation is eliminating human decision-making altogether. And in doing so, let's be clear, neither bias nor error are removed; rather they are often re-inscribed.  Automation -- *algorithmic* decision-making -- can obscure error; it can obscure bias.

This push for more automated decision-making works hand-in-hand with the push for more data collection, itself a process that is already shaped by precedent and by politics. And all this, of course, is facilitated by APIs.

APIs are commonly referred to as a "glue" of sorts -- the implication, more often than not, is that APIs are simply a neutral technology holding larger technical systems together. But none of this is neutral -- not the APIs and not the algorithms and not the databases.

These technologies are never neutral in their design, development, or implementation. The systems that technologies exist in -- organizationally, economically, politically, culturally -- are never neutral either.

It seems imperative that those building digital technologies begin to think much more critically about the implications of their work, recognizing that the existing inequalities in the analog systems are readily being ported to the digital sphere.

This makes the work of one of the keynote speakers at this fall's API Strategy and Practice conference so particularly timely: Virginia Eubanks is a political science professor at the University of Albany, SUNY and the author of Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. The book is a powerful work of ethnography, chronicling the ways in which data mining, predictive modeling, and algorithmic decision-making reproduce and even exacerbate inequalities in housing, health care, and social welfare services. "The digital poorhouse" Eubanks calls it.

"When we talk about the technologies that mediate our interactions with public agencies today," she writes, "we tend to focus on their innovative qualities, the ways they break with convention. Their biggest fans call them 'disruptors,' arguing that they shake up old relations of power, producing government that is more transparent, responsive, efficient, even inherently more democratic." This argument overlooks the ways in which new technologies are necessarily entangled in old systems of power. Moreover, those building these technologies benefit from a privilege that both shields them from and blinds them to the ramifications of their work on those most marginalized politically and economically.

Without a purposeful effort to address systemic inequalities, technologies will only make things worse. APIs will only make things worse. Instead, we must be part of the work of rethinking these old systems, listening to those on the margins, and reorienting our technological practices towards equity and justice.
